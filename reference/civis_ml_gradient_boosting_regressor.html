<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>CivisML Gradient Boosting Regressor — civis_ml_gradient_boosting_regressor • civis</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->
<link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" crossorigin="anonymous">

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script>
<script src="../pkgdown.js"></script>



<meta property="og:title" content="CivisML Gradient Boosting Regressor — civis_ml_gradient_boosting_regressor" />

<meta property="og:description" content="CivisML Gradient Boosting Regressor" />
<meta name="twitter:card" content="summary" />


<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">civis</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">1.4.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/civis_ml.html">Machine Learning in R with CivisML</a>
    </li>
    <li>
      <a href="../articles/concurrency.html">Making Simultaneous Calls to Platform</a>
    </li>
    <li>
      <a href="../articles/data_import_and_export.html">Data Import and Export</a>
    </li>
    <li>
      <a href="../articles/quick_start.html">Getting Started</a>
    </li>
  </ul>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/civisanalytics/civis-r">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>CivisML Gradient Boosting Regressor</h1>
    <small class="dont-index">Source: <a href='https://github.com/civisanalytics/civis-r/blob/master/R/civis_ml_workflows.R'><code>R/civis_ml_workflows.R</code></a></small>
    <div class="hidden name"><code>civis_ml_gradient_boosting_regressor.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>CivisML Gradient Boosting Regressor</p>
    
    </div>

    <pre class="usage"><span class='fu'>civis_ml_gradient_boosting_regressor</span>(<span class='no'>x</span>, <span class='no'>dependent_variable</span>,
  <span class='kw'>primary_key</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>excluded_columns</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>loss</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"ls"</span>, <span class='st'>"lad"</span>,
  <span class='st'>"huber"</span>, <span class='st'>"quantile"</span>), <span class='kw'>learning_rate</span> <span class='kw'>=</span> <span class='fl'>0.1</span>, <span class='kw'>n_estimators</span> <span class='kw'>=</span> <span class='fl'>500</span>,
  <span class='kw'>subsample</span> <span class='kw'>=</span> <span class='fl'>1</span>, <span class='kw'>criterion</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"friedman_mse"</span>, <span class='st'>"mse"</span>, <span class='st'>"mae"</span>),
  <span class='kw'>min_samples_split</span> <span class='kw'>=</span> <span class='fl'>2</span>, <span class='kw'>min_samples_leaf</span> <span class='kw'>=</span> <span class='fl'>1</span>,
  <span class='kw'>min_weight_fraction_leaf</span> <span class='kw'>=</span> <span class='fl'>0</span>, <span class='kw'>max_depth</span> <span class='kw'>=</span> <span class='fl'>2</span>, <span class='kw'>min_impurity_split</span> <span class='kw'>=</span> <span class='fl'>1e-07</span>,
  <span class='kw'>random_state</span> <span class='kw'>=</span> <span class='fl'>42</span>, <span class='kw'>max_features</span> <span class='kw'>=</span> <span class='st'>"sqrt"</span>, <span class='kw'>alpha</span> <span class='kw'>=</span> <span class='fl'>0.9</span>,
  <span class='kw'>max_leaf_nodes</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>presort</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"auto"</span>, <span class='fl'>TRUE</span>, <span class='fl'>FALSE</span>),
  <span class='kw'>fit_params</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>cross_validation_parameters</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>oos_scores_table</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>oos_scores_db</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>oos_scores_if_exists</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='st'>"fail"</span>, <span class='st'>"append"</span>, <span class='st'>"drop"</span>, <span class='st'>"truncate"</span>),
  <span class='kw'>model_name</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>cpu_requested</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>memory_requested</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>disk_requested</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>notifications</span> <span class='kw'>=</span> <span class='kw'>NULL</span>, <span class='kw'>polling_interval</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>verbose</span> <span class='kw'>=</span> <span class='fl'>FALSE</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>x</th>
      <td><p>See the Data Sources section below.</p></td>
    </tr>
    <tr>
      <th>dependent_variable</th>
      <td><p>The dependent variable of the training dataset.
For a multi-target problem, this should be a vector of column names of
dependent variables. Nulls in a single dependent variable will
automatically be dropped.</p></td>
    </tr>
    <tr>
      <th>primary_key</th>
      <td><p>Optional, the unique ID (primary key) of the training
dataset. This will be used to index the out-of-sample scores. In
<code>predict.civis_ml</code>, the primary_key of the training task is used by
default <code>primary_key = NA</code>. Use <code>primary_key = NULL</code> to
explicitly indicate the data have no primary_key.</p></td>
    </tr>
    <tr>
      <th>excluded_columns</th>
      <td><p>Optional, a vector of columns which will be
considered ineligible to be independent variables.</p></td>
    </tr>
    <tr>
      <th>loss</th>
      <td><p>The loss function to be optimized. <code>ls</code> refers to least
squares regression. <code>lad</code> (least absolute deviation) is a highly
robust loss function solely based on order information of the input
variables. <code>huber</code> is a combination of the two. <code>quantile</code>
allows quantile regression (use <code>alpha</code> to specify the quantile).</p></td>
    </tr>
    <tr>
      <th>learning_rate</th>
      <td><p>The learning rate shrinks the contribution of each tree
by <code>learning_rate</code>. There is a trade-off between <code>learning_rate</code>
and <code>n_estimators</code>.</p></td>
    </tr>
    <tr>
      <th>n_estimators</th>
      <td><p>The number of boosting stages to perform. Gradient
boosting is fairly robust to over-fitting, so a large number usually
results in better predictive performance.</p></td>
    </tr>
    <tr>
      <th>subsample</th>
      <td><p>The fraction of samples to be used for fitting individual
base learners. If smaller than 1.0, this results in Stochastic Gradient
Boosting. <code>subsample</code> interacts with the parameter <code>n_estimators</code>.
Choosing <code>subsample &lt; 1.0</code> leads to a reduction of variance and an
increase in bias.</p></td>
    </tr>
    <tr>
      <th>criterion</th>
      <td><p>The function to measure the quality of a split. The default
value <code>criterion = "friedman_mse"</code> is generally the best as it can
provide a better approximation in some cases.</p></td>
    </tr>
    <tr>
      <th>min_samples_split</th>
      <td><p>The minimum number of samples required to split
an internal node. If an integer, then consider <code>min_samples_split</code>
as the minimum number. If a float, then <code>min_samples_split</code> is a
percentage and <code>ceiling(min_samples_split * n_samples)</code> are the
minimum number of samples for each split.</p></td>
    </tr>
    <tr>
      <th>min_samples_leaf</th>
      <td><p>The minimum number of samples required to be in
a leaf node. If an integer, then consider <code>min_samples_leaf</code> as the
minimum number. If a float, the <code>min_samples_leaf</code> is a percentage
and <code>ceiling(min_samples_leaf * n_samples)</code> are the minimum number
of samples for each leaf node.</p></td>
    </tr>
    <tr>
      <th>min_weight_fraction_leaf</th>
      <td><p>The minimum weighted fraction of the sum
total of weights required to be at a leaf node.</p></td>
    </tr>
    <tr>
      <th>max_depth</th>
      <td><p>Maximum depth of the individual regression estimators. The
maximum depth limits the number of nodes in the tree. Tune this parameter
for best performance. The best value depends on the interaction of the
input variables.</p></td>
    </tr>
    <tr>
      <th>min_impurity_split</th>
      <td><p>Threshold for early stopping in tree growth. A node
will split if its impurity is above the threshold, otherwise it is a leaf.</p></td>
    </tr>
    <tr>
      <th>random_state</th>
      <td><p>The seed of the random number generator.</p></td>
    </tr>
    <tr>
      <th>max_features</th>
      <td><p>The number of features to consider when looking for the
best split.</p><dl class='dl-horizontal'>
  <dt>integer</dt><dd><p>consider <code>max_features</code> at each split.</p></dd>
  <dt>float</dt><dd><p>then <code>max_features</code> is a percentage and
    <code>max_features * n_features</code> are considered at each split.</p></dd>
  <dt>auto</dt><dd><p>then <code>max_features = sqrt(n_features)</code></p></dd>
  <dt>sqrt</dt><dd><p>then <code>max_features = sqrt(n_features)</code></p></dd>
  <dt>log2</dt><dd><p>then <code>max_features = log2(n_features)</code></p></dd>
  <dt>NULL</dt><dd><p>then <code>max_features = n_features</code></p></dd>
</dl></td>
    </tr>
    <tr>
      <th>alpha</th>
      <td><p>The alpha-quantile of the <code>huber</code> loss function and the
<code>quantile</code> loss function. Ignored unless <code>loss = "huber"</code> or
<code>loss = "quantile"</code></p></td>
    </tr>
    <tr>
      <th>max_leaf_nodes</th>
      <td><p>Grow trees with <code>max_leaf_nodes</code> in best-first
fashion. Best nodes are defined as relative reduction to impurity. If
<code>max_leaf_nodes = NULL</code> then unlimited number of leaf nodes.</p></td>
    </tr>
    <tr>
      <th>presort</th>
      <td><p>Whether to presort the data to speed up the finding of best
splits in fitting.</p></td>
    </tr>
    <tr>
      <th>fit_params</th>
      <td><p>Optional, a mapping from parameter names in the model's
<code>fit</code> method to the column names which hold the data, e.g.
<code>list(sample_weight = 'survey_weight_column')</code>.</p></td>
    </tr>
    <tr>
      <th>cross_validation_parameters</th>
      <td><p>Optional, parameter grid for learner
parameters, e.g. <code>list(n_estimators = c(100, 200, 500),
learning_rate = c(0.01, 0.1), max_depth = c(2, 3))</code>
or <code>"hyperband"</code> for supported models.</p></td>
    </tr>
    <tr>
      <th>oos_scores_table</th>
      <td><p>Optional, if provided, store out-of-sample
predictions on training set data to this Redshift "schema.tablename".</p></td>
    </tr>
    <tr>
      <th>oos_scores_db</th>
      <td><p>Optional, the name of the database where the
<code>oos_scores_table</code> will be created. If not provided, this will default
to <code>database_name</code>.</p></td>
    </tr>
    <tr>
      <th>oos_scores_if_exists</th>
      <td><p>Optional, action to take if
<code>oos_scores_table</code> already exists. One of <code>"fail"</code>, <code>"append"</code>, <code>"drop"</code>, or <code>"truncate"</code>.
The default is <code>"fail"</code>.</p></td>
    </tr>
    <tr>
      <th>model_name</th>
      <td><p>Optional, the prefix of the Platform modeling jobs.
It will have <code>" Train"</code> or <code>" Predict"</code> added to become the Script title.</p></td>
    </tr>
    <tr>
      <th>cpu_requested</th>
      <td><p>Optional, the number of CPU shares requested in the
Civis Platform for training jobs or prediction child jobs.
1024 shares = 1 CPU.</p></td>
    </tr>
    <tr>
      <th>memory_requested</th>
      <td><p>Optional, the memory requested from Civis Platform
for training jobs or prediction child jobs, in MiB.</p></td>
    </tr>
    <tr>
      <th>disk_requested</th>
      <td><p>Optional, the disk space requested on Civis Platform
for training jobs or prediction child jobs, in GB.</p></td>
    </tr>
    <tr>
      <th>notifications</th>
      <td><p>Optional, model status notifications. See
<code><a href='scripts_post_custom.html'>scripts_post_custom</a></code> for further documentation about email
and URL notification.</p></td>
    </tr>
    <tr>
      <th>polling_interval</th>
      <td><p>Check for job completion every this number of seconds.</p></td>
    </tr>
    <tr>
      <th>verbose</th>
      <td><p>Optional, If <code>TRUE</code>, supply debug outputs in Platform
logs and make prediction child jobs visible.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A <code>civis_ml</code> object, a list containing the following elements:</p>
<dt>job</dt><dd><p>job metadata from <code><a href='scripts_get_custom.html'>scripts_get_custom</a></code>.</p></dd>
<dt>run</dt><dd><p>run metadata from <code><a href='scripts_get_custom_runs.html'>scripts_get_custom_runs</a></code>.</p></dd>
<dt>outputs</dt><dd><p>CivisML metadata from <code><a href='scripts_list_custom_runs_outputs.html'>scripts_list_custom_runs_outputs</a></code> containing the locations of
 files produced by CivisML e.g. files, projects, metrics, model_info, logs, predictions, and estimators.</p></dd>
<dt>metrics</dt><dd><p>Parsed CivisML output from <code>metrics.json</code> containing metadata from validation.
 A list containing the following elements:
  <ul>
<li><p>run list, metadata about the run.</p></li>
<li><p>data list, metadata about the training data.</p></li>
<li><p>model list, the fitted scikit-learn model with CV results.</p></li>
<li><p>metrics list, validation metrics (accuracy, confusion, ROC, AUC, etc).</p></li>
<li><p>warnings list.</p></li>
<li><p>data_platform list, training data location.</p></li>
</ul></p></dd>
<dt>model_info</dt><dd><p>Parsed CivisML output from <code>model_info.json</code> containing metadata from training.
 A list containing the following elements:
  <ul>
<li><p>run list, metadata about the run.</p></li>
<li><p>data list, metadata about the training data.</p></li>
<li><p>model list, the fitted scikit-learn model.</p></li>
<li><p>metrics empty list.</p></li>
<li><p>warnings list.</p></li>
<li><p>data_platform list, training data location.</p></li>
</ul></p></dd>

    
    <h2 class="hasAnchor" id="data-sources"><a class="anchor" href="#data-sources"></a>Data Sources</h2>

    
    <p>For building models with <code>civis_ml</code>, the training data can reside in
four different places, a file in the Civis Platform, a CSV or feather-format file
on the local disk, a <code>data.frame</code> resident in local the R environment, and finally,
a table in the Civis Platform. Use the following helpers to specify the
data source when calling <code>civis_ml</code>:</p>
<dl class='dl-horizontal'>
  <dt><code>data.frame</code></dt><dd><p><code>civis_ml(x = df, ...)</code></p></dd>
  <dt>local csv file</dt><dd><p><code>civis_ml(x = "path/to/data.csv", ...)</code></p></dd>
  <dt>file in Civis Platform</dt><dd><p><code>civis_ml(x = civis_file(1234))</code></p></dd>
  <dt>table in Civis Platform</dt><dd><p><code>civis_ml(x = civis_table(table_name = "schema.table", database_name = "database"))</code></p></dd>
</dl>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><span class='co'># NOT RUN {</span>
<span class='fu'>data</span>(<span class='no'>ChickWeight</span>)

<span class='no'>m</span> <span class='kw'>&lt;-</span> <span class='fu'>civis_ml_gradient_boosting_regressor</span>(<span class='no'>ChickWeight</span>,
  <span class='kw'>dependent_variable</span> <span class='kw'>=</span> <span class='st'>"weight"</span>,
  <span class='kw'>learning_rate</span> <span class='kw'>=</span> <span class='fl'>.01</span>,
  <span class='kw'>n_estimators</span> <span class='kw'>=</span> <span class='fl'>100</span>,
  <span class='kw'>subsample</span> <span class='kw'>=</span> <span class='fl'>.5</span>,
  <span class='kw'>max_depth</span> <span class='kw'>=</span> <span class='fl'>5</span>,
  <span class='kw'>max_features</span> <span class='kw'>=</span> <span class='kw'>NULL</span>)
<span class='no'>yhat</span> <span class='kw'>&lt;-</span> <span class='fu'><a href='fetch_oos_scores.html'>fetch_oos_scores</a></span>(<span class='no'>m</span>)

<span class='co'># Grid Search</span>
<span class='no'>cv_params</span> <span class='kw'>&lt;-</span> <span class='fu'>list</span>(
  <span class='kw'>n_estimators</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='fl'>100</span>, <span class='fl'>200</span>, <span class='fl'>500</span>),
  <span class='kw'>learning_rate</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='fl'>.01</span>, <span class='fl'>.1</span>),
  <span class='kw'>max_depth</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='fl'>2</span>, <span class='fl'>3</span>))

<span class='no'>m</span> <span class='kw'>&lt;-</span> <span class='fu'>civis_ml_gradient_boosting_regressor</span>(<span class='no'>ChickWeight</span>,
  <span class='kw'>dependent_variable</span> <span class='kw'>=</span> <span class='st'>"weight"</span>,
  <span class='kw'>subsample</span> <span class='kw'>=</span> <span class='fl'>.5</span>,
  <span class='kw'>max_features</span> <span class='kw'>=</span> <span class='kw'>NULL</span>,
  <span class='kw'>cross_validation_parameters</span> <span class='kw'>=</span> <span class='no'>cv_params</span>)

<span class='no'>pred_info</span> <span class='kw'>&lt;-</span> <span class='fu'>predict</span>(<span class='no'>m</span>,  <span class='fu'><a href='civis_table.html'>civis_table</a></span>(<span class='st'>"schema.table"</span>, <span class='st'>"my_database"</span>),
   <span class='kw'>output_table</span> <span class='kw'>=</span> <span class='st'>"schema.scores_table"</span>)
<span class='co'># }</span></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#data-sources">Data Sources</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Patrick Miller, Keith Ingersoll.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  

  </body>
</html>

