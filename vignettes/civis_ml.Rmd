---
title: "Modeling with CivisML"
author: "Patrick Miller"
date: "2017-08-29"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{civis_ml}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

CivisML is a machine learning service on Civis Platform. It allows you to fit many different models, do extensive meta-parameter tuning, and score data sets with millions of rows on AWS rather than your local machine. Results and plots are stored in Civis Platform, and can be easily shared with decision makers. The models themselves can also be stored, re-run, scheduled, and shared with other data scientists. [This blog post](https://www.civisanalytics.com/blog/civisml-scikit-learn-at-scale/) provides an excellent summary of the rich set of features in CivisML.

CivisML is built in Python using scikit-learn. However, most of its features can be used through R without installing Python or any other dependencies using the `civis_ml` function in `civis`. It's possible to write sophisticated modeling workflows by combining `civis_ml` with other IO, reporting, and API functions in `civis`. 

In the following, we will highlight the modeling feautures of `civis_ml`. While `civis_ml` is a complex function with many arguments, basic machine learning modeling and scoring can be easily carried out easily. We illustrate several features of `civis_ml` with data from a fictious company called Brandable, who is looking to predict which customers are likely to upgrade from the free to the premium service.

## Data sources

The first step of modeling with `civis_ml` is to specify the data source, which is the first argument. `civis_ml` works with local data frames, a CSV on local disk, tables in Redshift, and files on S3 (the files endpoint):

```{r, eval = FALSE}
library(civis)
civis_ml(df, ...)
civis_ml("path/to/data.csv", ...)
civis_ml(civis_table(table_name = "schema.table", database_name = "database"), ...)
civis_ml(civis_file(1234), ...)
```

The Brandable data is located in a Redshift table called `sample_project.premium_training_set`:

```{r, eval  = FALSE}
tab <- civis_table("sample_project.premium_training_set", "redshift-general")
```

Note that `civis_table` only returns information on where to find the data for `civis_ml`, not the data itself. `civis_table` also takes two SQL statements that can be useful for limiting the rows used for training: `sql_where`, and `sql_limit`. 

### Missing data

Modeling data must be complete. Any missing values will be imputed with the mean of non-null values in a column. 

## Modeling

After the data source is specified, we next choose the model type. There are 9 named CivisML models that can be called from `civis_ml`, 4 for classification and 5 for regression. The name of the model corresponds to the name of the estimator in scikit-learn. It can be given in the `model_type` argument of `civis_ml`, or called directly using a `civis_ml_*` function such as `civis_ml_sparse_logistic`.

| Name | R Workflow | Model Type | scikit-learn Documentation |
|------|:-----------|------------|-----------|------------------|
  `sparse_logistic`	| `civis_ml_sparse_logistic` | classification	| [Logistic Regression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)	|
  `gradient_boosting_classifier` |	`civis_ml_gradient_boosting_classifier` | classification |	[GradientBoostingClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html) |
  `random_forest_classifier` |	`civis_ml_random_forest_classifier` | classification |	[RandomForestClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) | 
  `extra_trees_classifier` |	`civis_ml_extra_trees_classifier` | classification |	[ExtraTreesClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html)|
  `sparse_linear_regressor` | `civis_ml_sparse_linear_regressor` |	regression |	[LinearRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) |
  `sparse_ridge_regressor` |	`civis_ml_sparse_ridge_regressor` | regression |	[Ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) |
  `gradient_boosting_regressor`	| `civis_ml_gradient_boosting_regressor` | regression | [GradientBoostingRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) |
  `random_forest_regressor`	| `civis_ml_random_forest_regressor` | regression | [RandomForestRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)|
  `extra_trees_regressor` | `civis_ml_extra_trees_regressor` | regression	| [ExtraTreesRegressor](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html) 

Documentation on the meta parameters specific to each estimator are provided in `?civis_ml_*`. For example, the regularization strength parameter `C` of `sparse_logistic` is documented in `?civis_ml_sparse_logistic`.

For the brandable data, we use a `random_forest` classifier to predict the probability that a customer upgrades from free to premium services. For efficiency, we can also denote a `primary_key`, and a set of `excluded_columns` that are not included in the model:


```{r, eval = FALSE}
library(civis)
tab <- civis_table("sample_project.premium_training_set", "redshift-general")
m   <- civis_ml(tab, dependent_variable = "upgrade", 
                model_type = "random_fest_classifier", 
                primary_key = "brandable_user_id", 
                excluded_columns = "residential_zip")
```

### Metaparameter Tuning

CivisML takes care of metaparameter tuning by evaluating the performance of the classifier over the grid created from all combinations of candidate values. Any metaparameter provided by scikit-learn can be included in this search. Evaluation is carried out in parallel using 4-fold CV. 

For the `random_forest_classifier` in the brandable data, we specify a search grid over `max_depth` and `n_estimators`:

```{r, eval = FALSE}
tab       <- civis_table("sample_project.premium_training_set", "redshift-general")
cv_params <- list("max_depth" = c(2, 3, 5), 
                  "n_estimators" = c(50, 100, 500))
  
m <- civis_ml(tab, dependent_variable = "upgrade", 
              model_type = "random_fest_classifier", 
              primary_key = "brandable_user_id", 
              excluded_columns = "residential_zip", 
              cross_validation_parameters = cv_params)
```


## Results

A simple summary of the results is provided with `print`:

```{r, eval=FALSE}
m
```


```{r run_model, eval=FALSE, echo=FALSE}
# use this chunk to actually update the model if necessary
library(civis)
tab       <- civis_table("sample_project.premium_training_set", "redshift-general")
cv_params <- list("max_depth" = c(2, 3, 5), 
                "n_estimators" = c(50, 100, 500))
  

m <- civis_ml(tab, dependent_variable = "upgrade", 
              model_type = "random_forest_classifier", 
              primary_key = "brandable_user_id", 
              excluded_columns = "residential_zip", 
              cross_validation_parameters = cv_params)
saveRDS(m, file = "../inst/civis_ml_brandable.rds")

oos <- fetch_oos_scores(m)
saveRDS(oos, file = "../inst/civis_ml_oos.rds")

err_m <- tryCatch({
  civis_ml(tab, dependent_variable = "upgrade", 
           model_type = "random_fest_classifier", 
           primary_key = "brandable_user_id", 
           excluded_columns = "residential_zip", 
           cross_validation_parameters = cv_params)
  }, error = function(e) e)
saveRDS(err_m, file = "../inst/civis_ml_err.rds")

```

```{r, eval=TRUE, echo=FALSE}
library(civis)
m <- readRDS("../inst/civis_ml_brandable.rds")
m
```
Following the link takes you to a summary of the model results in Civis Platform. Additional metrics can be computed with `get_metric`:

```{r}
get_metric(m, "accuracy")
get_metric(m, "confusion_matrix")
get_metric(m, "roc_auc")
```

Out of sample (or out of fold) scores used in training can be retrieved using `fetch_oos_scores`:

```{r, echo=TRUE, eval=FALSE}
oos <- fetch_oos_scores(m)
head(oos)
```

```{r, echo=FALSE, eval=TRUE}
oos <- readRDS("../inst/civis_ml_oos.rds")
head(oos)
```

## Diagnostics 

For classification problems, `plot` produces a a decile plot using `ggplot2`. For the premium upgrade model, the decile plot shows that the top-scoring 10\% of individuals contain 2.20 times as many targets (people who upgraded) as a randomly selected list of the same size.

```{r, fig.width = 5}
plot(m)
```

For regression problems, `plot` produces a binned scatter-plot of $y$ against $\hat{y}$.

`hist` shows the histogram of out of sample (out of fold scores), also using `ggplot2`:

```{r}
hist(m)
```

Plots can be further customized using ggplot2 `+` operator.

## Prediction and Scoring

CivisML can also be used to score models on hundreds of millions of rows, and distributed over many compute instances. Like many estimators in R, this is done through a `predict` method. The `newdata` argument of `predict` can take any data source supported in `civis_ml`. Here we use a table in Redshift containing all Brandable users, and output the result to another table in Redshift:

```{r, eval=FALSE}
pred_tab <- civis_table("sample_project.brandable_all_users", "redshift-general")
pred_job <- predict(m, newdata = pred_tab, 
                    output_table = "sample_project.brandable_user_scores")
```

For very large scoring jobs, the scoring can be distributed using `n_jobs`:

```{r, eval=FALSE}
pred_job <- predict(m, newdata = pred_tab, 
                    output_table = "sample_project.brandable_user_scores", 
                    n_jobs = 25)
```

The predictions can be loaded into memory using `fetch_predictions`, which downloads directly from S3:

```{r, eval=FALSE}
yhat <- fetch_predictions(pred_job)
```

Note that if the table of predictions exceeds available memory, it may be helpful to use `download_civis` instead.

```{r, eval=FALSE}
# download from S3
download_civis(pred_job$model_info$output_file_ids, path = "my_predictions.csv")

# download from Redshift 
download_civis("sample_project.brandable_user_scores", "redshift-general")
```

## Retrieving Existing models

An existing model (or particular run of an existing model) can be retrieved using `civis_ml_fetch_existing`:

```{r, eval=FALSE}
model_id <- m$job$id
m <- civis_ml_fetch_existing(model_id)
```

## Error Handling

Unfortunately, many kinds of errors can occur. When an error occurs within the CivisML, a `civis_ml_error` is thrown. By default, the log from the CivisML job is printed, which is useful for debugging.

Here is an example error from misspelling the model type:

```{r, eval=FALSE}
civis_ml(tab, dependent_variable = "upgrade", 
        model_type = "random_fest_classifier", 
        primary_key = "brandable_user_id", 
        excluded_columns = "residential_zip", 
        cross_validation_parameters = cv_params)
```

```{r, echo=FALSE, eval=TRUE}
err <- readRDS("../inst/civis_ml_err.rds")
err
```

If you don't understand the error message, providing the error message, job, and run ids to support is the best way to get help!

## Programming with `civis_ml`

When programming with `civis_ml`, errors can be caught using the base R `try` or `tryCatch`. In `civis`, we provide functions for getting debugging information using `get_error` or just the logs using `fetch_logs`. 

```{r, eval = FALSE}
e <- tryCatch({
  civis_ml(tab, dependent_variable = "upgrade", 
        model_type = "random_fest_classifier", 
        primary_key = "brandable_user_id", 
        excluded_columns = "residential_zip")
  }, civis_ml_error = function(e) e)
get_error(e)
fetch_logs(e)
```

Error handling can be used to implement more robust workflow programming with `civis_ml`. Handler functions can be used to write error logs to a database or file. In the following function, we implement `retry_model`, which retries on e.g. connection failures but not on a `civis_ml_error`.

```{r, eval=FALSE}
retry_model <- function(max_retries = 5) {
  i <- 1
  while (i < max_retries) {
    tryCatch({
      m <- civis_ml(tab, dependent_variable = "upgrade", 
               model_type = "random_forest_classifier", 
               primary_key = "brandable_user_id", 
               excluded_columns = "residential_zip")
      return(m)
    }, civis_ml_error = function(e) stop(e))
    cat("Retry: ", i, fill = TRUE)
    i <- i + 1
  }
  stop("Exceeded maximum retries.")
}
```


## Appendix 

### Parallelization

To fit many models in parallel using `parallel`, `foreach`, or `future`, check out [this article](https://civisanalytics.github.io/civis-r/articles/concurrency.html) or the vignette on concurrency at `browseVignettes("civis")`.

### Sample weights

Many estimators take a `sample_weight` argument. This can be be specified with the `fit_params` argument of `civis_ml` using `list(sample_weight = 'survey_weight_column')`.

### More information

The `sparse_logistic`, `sparse_linear_regressor`, and `sparse_ridge_regressor` models all use the public Civis Analytics [glmnet](https://github.com/civisanalytics/python-glmnet) wrapper in Python.

Browse [the CivisML documentation](https://civis-python.readthedocs.io/en/v1.6.1/ml.html) for more details.

