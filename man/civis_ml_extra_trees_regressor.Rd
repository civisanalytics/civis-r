% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/civis_ml_workflows.R
\name{civis_ml_extra_trees_regressor}
\alias{civis_ml_extra_trees_regressor}
\title{CivisML Extra Trees Regressor}
\usage{
civis_ml_extra_trees_regressor(x, dependent_variable, primary_key = NULL,
  excluded_columns = NULL, n_estimators = 500, criterion = c("mse",
  "mae"), max_depth = NULL, min_samples_split = 2, min_samples_leaf = 1,
  min_weight_fraction_leaf = 0, max_features = "sqrt",
  max_leaf_nodes = NULL, min_impurity_split = 1e-07, bootstrap = FALSE,
  random_state = 42, fit_params = NULL,
  cross_validation_parameters = NULL, oos_scores_table = NULL,
  oos_scores_db = NULL, oos_scores_if_exists = c("fail", "append", "drop",
  "truncate"), model_name = NULL, cpu_requested = NULL,
  memory_requested = NULL, disk_requested = NULL, notifications = NULL,
  polling_interval = NULL, verbose = FALSE)
}
\arguments{
\item{x}{See the Data Sources section below.}

\item{dependent_variable}{The dependent variable of the training dataset.
For a multi-target problem, this should be a vector of column names of
dependent variables.}

\item{primary_key}{Optional, the unique ID (primary key) of the training
dataset. This will be used to index the out-of-sample scores. In
\code{predict.civis_ml}, the primary_key of the training task is used by
default \code{primary_key = NA}. Use \code{primary_key = NULL} to
explicitly indicate the data have no primary_key.}

\item{excluded_columns}{Optional, a vector of columns which will be
considered ineligible to be independent variables.}

\item{n_estimators}{The number of boosting stages to perform. Gradient
boosting is fairly robust to over-fitting, so a large number usually
results in better predictive performance.}

\item{criterion}{The function used to measure the quality of a split.
Supported criteria are \code{mse} for the mean squared error, and \code{mae}
for the mean absolute error.}

\item{max_depth}{Maximum depth of the individual regression estimators. The
maximum depth limits the number of nodes in the tree. Tune this parameter
for best performace. The best value depends on the interaction of the
input variables.}

\item{min_samples_split}{The minimum number of samples required to split
an internal node. If an integer, then consider \code{min_samples_split}
as the minimum number. If a float, then \code{min_samples_split} is a
percentage and \code{ceiling(min_samples_split * n_samples)} are the
minimum number of samples for each split.}

\item{min_samples_leaf}{The minumum number of samples required to be in
a leaf node. If an integer, then consider \code{min_samples_leaf} as the
minimum number. If a float, the \code{min_samples_leaf} is a percentage
and \code{ceiling(min_samples_leaf * n_samples)} are the minimum number
of samples for each leaf node.}

\item{min_weight_fraction_leaf}{The minimum weighted fraction of the sum
total of weights required to be at a leaf node.}

\item{max_features}{The number of features to consider when looking for the
best split.
\describe{
  \item{integer}{consider \code{max_features} at each split.}
  \item{float}{then \code{max_features} is a percentage and
    \code{max_features * n_features} are considered at each split.}
  \item{auto}{then \code{max_features = sqrt(n_features)}}
  \item{sqrt}{then \code{max_features = sqrt(n_features)}}
  \item{log2}{then \code{max_features = log2(n_features)}}
  \item{NULL}{then \code{max_features = n_features}}
}}

\item{max_leaf_nodes}{Grow trees with \code{max_leaf_nodes} in best-first
fashion. Best nodes are defined as relative reduction to impurity. If
\code{max_leaf_nodes = NULL} then unlimited number of leaf nodes.}

\item{min_impurity_split}{Threshold for early stopping in tree growth. A node
will split if its impurity is above the threshold, otherwise it is a leaf.}

\item{bootstrap}{Whether bootstrap samples are used when building trees.}

\item{random_state}{The seed of the random number generator.}

\item{fit_params}{Optional, a mapping from parameter names in the model's
\code{fit} method to the column names which hold the data, e.g.
\code{list(sample_weight = 'survey_weight_column')}.}

\item{cross_validation_parameters}{Optional, parameter grid for learner
parameters, e.g. \code{list(n_estimators = c(100, 200, 500),
learning_rate = c(0.01, 0.1), max_depth = c(2, 3))}.}

\item{oos_scores_table}{Optional, if provided, store out-of-sample
predictions on training set data to this Redshift "schema.tablename".}

\item{oos_scores_db}{Optional, the name of the database where the
\code{oos_scores_table} will be created. If not provided, this will default
to \code{database_name}.}

\item{oos_scores_if_exists}{Optional, action to take if
\code{oos_scores_table} already exists. The default is \code{"fail"}.}

\item{model_name}{Optional, the prefix of the Platform modeling jobs.
It will have " Train" or " Predict" added to become the Script title.}

\item{cpu_requested}{Optional, the number of CPU shares requested in the
Civis Platform for training jobs. 1024 shares = 1 CPU.}

\item{memory_requested}{Optional, the memory requested from Civis Platform
for training jobs, in MiB.}

\item{disk_requested}{Optional, the disk space requested on Civis Platform
for training jobs, in GB.}

\item{notifications}{Optional, model status notifications. See
\code{\link{scripts_post_custom}} for further documentation about email
and URL notification.}

\item{polling_interval}{Check for job completion every this number of seconds.}

\item{verbose}{Optional, If \code{TRUE}, supply debug outputs in Platform
logs and make prediction child jobs visible.}
}
\value{
A \code{civis_ml} object.
}
\description{
CivisML Extra Trees Regressor
}
\section{Data Sources}{


For building models with \code{civis_ml}, the training data can reside in
four different places, a file in the Civis Platform, a CSV file on the local
disk, a \code{data.frame} resident in local the R environment, and finally,
a table in the Civis Platform. Use the following helpers to specify the
data source when calling \code{civis_ml}:

\describe{
  \item{\code{data.frame}}{\code{civis_ml(x = df, ...)}}
  \item{local csv file}{\code{civis_ml(x = "path/to/data.csv", ...)}}
  \item{file in Civis Platform}{\code{civis_ml(x = civis_file(1234))}}
  \item{table in Civis Platform}{\code{civis_ml(x = civis_table(table_name = "schema.table", database_name = "database"))}}
}

A fitted model can be used to make predictions for data residing in any of
the sources above and a \code{\link{civis_file_manifest}}. Similar to
\code{civis_ml}, use the data source helpers as the \code{newdata} argument
to \code{predict.civis_ml}.
}

