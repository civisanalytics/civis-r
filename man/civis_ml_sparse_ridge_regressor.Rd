% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/civis_ml_workflows.R
\name{civis_ml_sparse_ridge_regressor}
\alias{civis_ml_sparse_ridge_regressor}
\title{CivisML Sparse Ridge Regression}
\usage{
civis_ml_sparse_ridge_regressor(x, dependent_variable, primary_key = NULL,
  excluded_columns = NULL, alpha = 1, fit_intercept = TRUE,
  normalize = FALSE, max_iter = NULL, tol = 0.001, solver = c("auto",
  "svd", "cholesky", "lsqr", "sparse_cg", "sag"), random_state = 42,
  fit_params = NULL, cross_validation_parameters = NULL,
  calibration = NULL, oos_scores_table = NULL, oos_scores_db = NULL,
  oos_scores_if_exists = c("fail", "append", "drop", "truncate"),
  model_name = NULL, cpu_requested = NULL, memory_requested = NULL,
  disk_requested = NULL, notifications = NULL, polling_interval = NULL,
  verbose = FALSE)
}
\arguments{
\item{x}{See the Data Sources section below.}

\item{dependent_variable}{The dependent variable of the training dataset.
For a multi-target problem, this should be a vector of column names of
dependent variables.}

\item{primary_key}{Optional, the unique ID (primary key) of the training
dataset. This will be used to index the out-of-sample scores. In
\code{predict.civis_ml}, the primary_key of the training task is used by
default \code{primary_key = NA}. Use \code{primary_key = NULL} to
explicitly indicate the data have no primary_key.}

\item{excluded_columns}{Optional, a vector of columns which will be
considered ineligible to be independent variables.}

\item{alpha}{The regularization strength, must be a vector of floats of
lenght n_targets or a single float. Larger values specify stronger
regularization.}

\item{fit_intercept}{Should an intercept term be included in the model. If
\code{FALSE}, no intercept will be included, in this case the data are
expected to already be centered.}

\item{normalize}{If \code{TRUE}, the regressors will be normalized before
fitting the model. \code{normalize} is ignored when
\code{fit_intercept = FALSE}.}

\item{max_iter}{Maximum number of iterations for conjugate gradient solver.
For \code{sparse_cg} and \code{lsqr} solvers, the default value is
predetermined. For the \code{sag} solver, the default value is 1000.}

\item{tol}{Precision of the solution.}

\item{solver}{Solver to use for the optimization problem.
\describe{
  \item{auto}{chooses the solver automatically based on the type of data.}
  \item{svd}{uses Singular Value Decomposition of X to compute the Ridge
    coefficients. More stable for singular matrices than \code{cholesky}.}
  \item{cholesky}{uses the standard decomposition to obtain a closed-form
    solution.}
  \item{sparse_cg}{uses the conjugate gradient solver. As an iterative
    algorithm, this solver is more appropriate than \code{cholesky} for
    large-scale data.}
  \item{lsqr}{uses the dedicated regularized least-squares routine.}
  \item{sag}{uses Stochastic Average Gradient descent. It also uses an
    iterative procedure, and is often faster than other solvers when both
    n_samples and n_features are large. Note that \code{sag} fast
    convergence is only guaranteed on features with approximately the same
    scale}
}}

\item{random_state}{The seed of the pseudo random number generator to use
when shuffling the data. Used only when \code{solver = "sag"}.}

\item{fit_params}{Optional, a mapping from parameter names in the model's
\code{fit} method to the column names which hold the data, e.g.
\code{list(sample_weight = 'survey_weight_column')}.}

\item{cross_validation_parameters}{Optional, parameter grid for learner
parameters, e.g. \code{list(n_estimators = c(100, 200, 500),
learning_rate = c(0.01, 0.1), max_depth = c(2, 3))}.}

\item{calibration}{Optional, if not \code{NULL}, calibrate output
probabilities with the selected method, \code{sigmoid}, or \code{isotonic}.
Valid only with classification models.}

\item{oos_scores_table}{Optional, if provided, store out-of-sample
predictions on training set data to this Redshift "schema.tablename".}

\item{oos_scores_db}{Optional, the name of the database where the
\code{oos_scores_table} will be created. If not provided, this will default
to \code{database_name}.}

\item{oos_scores_if_exists}{Optional, action to take if
\code{oos_scores_table} already exists. The default is \code{"fail"}.}

\item{model_name}{Optional, the prefix of the Platform modeling jobs.
It will have " Train" or " Predict" added to become the Script title.}

\item{cpu_requested}{Optional, the number of CPU shares requested in the
Civis Platform for training jobs. 1024 shares = 1 CPU.}

\item{memory_requested}{Optional, the memory requested from Civis Platform
for training jobs, in MiB.}

\item{disk_requested}{Optional, the disk space requested on Civis Platform
for training jobs, in GB.}

\item{notifications}{Optional, model status notifications. See
\code{\link{scripts_post_custom}} for further documentation about email
and URL notification.}

\item{polling_interval}{Check for job completion every this number of seconds.}

\item{verbose}{Optional, If \code{TRUE}, supply debug outputs in Platform
logs and make prediction child jobs visible.}
}
\value{
A \code{civis_ml} object.
}
\description{
CivisML Sparse Ridge Regression
}
\section{Data Sources}{


For building models with \code{civis_ml}, the training data can reside in
four different places, a file in the Civis Platform, a CSV file on the local
disk, a \code{data.frame} resident in local the R environment, and finally,
a table in the Civis Platform. Use the following helpers to specify the
data source when calling \code{civis_ml}:

\describe{
  \item{\code{data.frame}}{\code{civis_ml(x = df, ...)}}
  \item{local csv file}{\code{civis_ml(x = "path/to/data.csv", ...)}}
  \item{file in Civis Platform}{\code{civis_ml(x = civis_file(1234))}}
  \item{table in Civis Platform}{\code{civis_ml(x = civis_table(table_name = "schema.table", database_name = "database"))}}
}

A fitted model can be used to make predictions for data residing in any of
the sources above and a \code{\link{civis_file_manifest}}. Similar to
\code{civis_ml}, use the data source helpers as the \code{newdata} argument
to \code{predict.civis_ml}.
}

